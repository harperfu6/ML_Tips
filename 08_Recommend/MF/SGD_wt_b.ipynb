{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:11:00.481991Z",
     "start_time": "2019-08-28T00:10:59.510812Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:11:05.786723Z",
     "start_time": "2019-08-28T00:11:05.784046Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change default figure and font size\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:13:27.542887Z",
     "start_time": "2019-08-28T00:13:27.491955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = os.path.join('data', 'ml-100k')\n",
    "file_path = os.path.join(file_dir, 'u.data')\n",
    "\n",
    "if not os.path.isdir(file_dir):\n",
    "    call(['curl', '-O', 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'])\n",
    "    call(['unzip', 'ml-100k.zip'])\n",
    "    \n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(file_path, sep = '\\t', names=names)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T02:36:39.684814Z",
     "start_time": "2019-08-28T02:36:39.519831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensition:  (943, 1682)\n",
      "sparsity: 6.3%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the rating matrix r_{ui}\n",
    "# remember to subtract the user and item id by 1 since the indices starts from 0\n",
    "n_users = df['user_id'].unique().shape[0]\n",
    "n_items = df['item_id'].unique().shape[0]\n",
    "# initialize\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples(index=False): # iterrowよりも高速\n",
    "    ratings[row.user_id-1, row.item_id-1] = row.rating\n",
    "\n",
    "# compute the no-zero elements in the rating matrix\n",
    "matrix_size = np.prod(ratings.shape)\n",
    "interaction = np.flatnonzero(ratings).shape[0] # retrun \"indices\" tha are non-zero\n",
    "sparsity = (interaction/matrix_size) * 100\n",
    "\n",
    "print('dimensition: ', ratings.shape)\n",
    "print('sparsity: {:.1f}%'.format(sparsity))\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization with SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SGD, we again take derivatives of the loss function, but we take the derivative with respect to each variable in the model.  \n",
    "The “stochastic” aspect of the algorithm involves taking the derivative and updating feature weights one individual sample at a time.  \n",
    "So, for each sample, we take the derivative of each variable, set them all equal to zero, solve for the feature weights, and update each feature. Somehow this method actually converges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a similar loss function to before, but I am going to add some more details to the model.  \n",
    "Instead of assuming that a user u’s rating for item i can be described simply by the dot product of the user and item latent vectors, we will consider that each user and item can have a bias term associated with them. \n",
    "The rational is that certan users might tend to rate all movies highly, or certain movies may tend to always have low ratings.  \n",
    "The way that I think about it is that the bias term takes care of the “DC” part of the signal which allows the latent factors to account for the more detailed variance in signal (kind of like the AC part).  \n",
    "We will also include a global bias term as well. With all things combined, our predicted rating becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat r_{ui} = \\mu + \\vec{b_u} + \\vec{b_i} + \\vec{x_u}^T \\cdot \\vec{y_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mu$ is the global bias, and $\\vec{b_u}(\\vec{b_i})$ is the user (item) bias.  \n",
    "Our loss function now becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L = \\sum_{u,i}(\\vec{r_{ui}} - (\\mu + \\vec{b_u} + \\vec{b_i} + \\vec{x_u}^T \\cdot \\vec{y_i}))^2 + \\lambda_{xb}\\sum_u|\\vec{b_u}|^2 + \\lambda_{yb}\\sum_i|\\vec{b_i}|^2 + \\lambda_{xf}\\sum_u|\\vec{x_u}|^2 + \\lambda_{yf}\\sum_i|\\vec{y_i}|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we have added on extra bias regularization terms.  \n",
    "We want to update each feature (user and item latent factors and bias terms) with each sample.  \n",
    "The update for the user bias is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\vec{b_u}\\gets\\vec{b_u} - \\eta\\frac{\\partial L}{\\partial \\vec{b_u}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\eta$ is the learning rate which weights how much our update modifies the feature weights.  \n",
    "The derivative term is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial \\vec{b_u}} = 2(\\vec{r_{ui}} - (\\mu + \\vec{b_u} +\\vec{b_i} + \\vec{x_u}^T \\cdot \\vec{y_i}))(-1) + 2\\lambda_{xb}\\vec{b_u}$$\n",
    "$$\\frac{\\partial L}{\\partial \\vec{b_u}} = 2(\\vec{e_{ui}})(-1) + 2\\lambda_{xb}\\vec{b_u}$$\n",
    "$$\\frac{\\partial L}{\\partial \\vec{b_u}} = -\\vec{e_{ui}} + \\lambda_{xb}\\vec{b_u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where **$e_{ui}$ represents the error in our prediction** and we have dropped the factor of 2 (we can assume it gets rolled up in the learning rate). For all of our features, the updates end up being"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\vec{b_u}\\gets\\vec{b_u} + \\eta(\\vec{e_{ui}} - \\lambda_{xb}\\vec{b_u})$$\n",
    "$$\\vec{b_i}\\gets\\vec{b_i} + \\eta(\\vec{e_{ui}} - \\lambda_{yb}\\vec{b_i})$$\n",
    "$$\\vec{x_u}\\gets\\vec{x_u} + \\eta(\\vec{e_{ui}}\\vec{y_i} - \\lambda_{xf}\\vec{x_u})$$\n",
    "$$\\vec{y_i}\\gets\\vec{y_i} + \\eta(\\vec{e_{ui}}\\vec{x_u} - \\lambda_{yf}\\vec{y_i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T04:36:09.372300Z",
     "start_time": "2019-08-28T04:36:09.359043Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExplictMF():\n",
    "    \"\"\"\n",
    "    Train a matrix factorization mode to predict empty entries in a matrix.\n",
    "    Te terminology assumes a ratings matrix which is ~ user x item\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    ratings : ndarray\n",
    "        user x Item matrix with corresponding ratings\n",
    "    \n",
    "    n_factors : int\n",
    "        number of latent factors to use in matrix\n",
    "        factorization model, some machine-learning libraries denote this as 'rank'\n",
    "        \n",
    "    learnig : str\n",
    "        method of optimization. \n",
    "        options include 'sgd' of 'als'.\n",
    "        \n",
    "    item_fact_reg : float\n",
    "        regularization term for item latent factors\n",
    "        \n",
    "    user_fact_reg : float\n",
    "        regularization term for user latent factors\n",
    "        \n",
    "    item_bias_reg : float\n",
    "        regularization term for item biases\n",
    "        \n",
    "    user_bias_reg : float\n",
    "        regularization term for user biases\n",
    "        \n",
    "    verbose : bool\n",
    "        whether or not to printout training progress\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ratings, n_factors=40, learning='sgd',\n",
    "                     item_fact_reg=0.0, user_fact_reg=0.0, item_bias_reg=0.0, user_bias_reg=0.0,\n",
    "                    verbose=False):\n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = rating.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_fact_reg = item_fact_reg\n",
    "        self.user_fact_reg = user_fact_reg\n",
    "        self.item_bias_reg = item_bias_reg\n",
    "        self.user_bias_reg = user_bias_reg\n",
    "        self.learning = learnig\n",
    "        \n",
    "        if self.learning == 'sgd':\n",
    "            self.sample_row, self.sample_col = self.ratings.nonzero() # nonzeroのindexを返す\n",
    "            self.n_samples = len(self.sample_row)\n",
    "        self._v = verbose\n",
    "        \n",
    "        \n",
    "    def train(self, n_iter=10, learning_rate=0.1):\n",
    "        # initrialize model for n_iter iterations from scratch\n",
    "        self.user_vecs = np.random.normal(scale=1./self.n_factors, size=(self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.normal(scale=1./self.n_factors, size=(self.n_items, self.n_factors))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.user_bias = np.zeros(self.n_users)\n",
    "        self.item_bias = np.zeros(self.n_items)\n",
    "        self.global_bias = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "        self.partial_train(n_iter)\n",
    "        \n",
    "        \n",
    "    def partial_train(self, n_iter):\n",
    "        \"\"\"\n",
    "        Train model for n_iter iterations.\n",
    "        Can be called multiple times for further training.\n",
    "        \"\"\"\n",
    "        self.test_mse_record = []\n",
    "        self.train_mse_record = []\n",
    "        ctr = 1\n",
    "        while ctr <= n_iter:\n",
    "            if ctr % 10 == 0 and self._v:\n",
    "                print('\\tcurrent iteration: {}'.format(ctr))\n",
    "            \n",
    "            self.training_indices = np.arrange(self.n_samples)\n",
    "            np.random.shuffle(self.training_indices)\n",
    "            self.sgd()\n",
    "            \n",
    "            ctr += 1\n",
    "        \n",
    "        \n",
    "    def sgd(self):\n",
    "        for idx in self.training_indices:\n",
    "            u = self.sample_row[idx]\n",
    "            i = self.sample_col[idx]\n",
    "            prediction = self.predict(u, i)\n",
    "            \n",
    "            e = (self.ratings[u, i] - prediction) # error\n",
    "            \n",
    "            # Update bias\n",
    "            self.user_bias[u] += self.learning_rate * (e - self.user_bias_reg * self.user_bias[u])\n",
    "            self.item_bias[i] += self.learning_rate * (e - self.item_bias_reg * self.item_bias[i])\n",
    "            \n",
    "            # Update latent factors\n",
    "            self.user_vecs[u, :] += self.learning_rate * (e *  self.item_vecs[i, :] - self.user_fact_reg * self.user_vecs[u, :])\n",
    "            self.item_vecs[i :] += self.learning_rate * (e *  self.user_vecs[u, :] - self.item_fact_reg * self.item_vecs[i, :])\n",
    "            \n",
    "            \n",
    "    def predict(self, u, i):\n",
    "        \"\"\"\n",
    "        SIngle user and item prediction.\n",
    "        \"\"\"\n",
    "        prediction = self.global_bias + self.user_bias[u] + self.item_bias[i] + self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_mse(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        ignore zero terms prior to comparing the mse\n",
    "        \"\"\"\n",
    "        mask = np.nonzero(y_true)\n",
    "        mse = mean_squared_error(y_true[mask], y_pred[mask])\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T04:36:33.531845Z",
     "start_time": "2019-08-28T04:36:33.528348Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(model):\n",
    "    \"\"\"\n",
    "    visualize the training/testing loss\n",
    "    \"\"\"\n",
    "    linewidth = 3\n",
    "    plt.plot(model.test_mse_record, label='Test', linewidth=linewidth)\n",
    "    plt.plot(model.train_mse_record, label='Train', linewidth=linewidth)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
