{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternating Least Squares with Weighted Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T01:24:23.798548Z",
     "start_time": "2019-08-27T01:23:49.220103Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T01:33:43.697032Z",
     "start_time": "2019-08-27T01:33:43.694578Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change default figure and font size\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T01:24:31.123434Z",
     "start_time": "2019-08-27T01:24:28.504680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = 'ml-100k'\n",
    "file_path = os.path.join(file_dir, 'u.data')\n",
    "\n",
    "if not os.path.isdir(file_dir):\n",
    "    call(['curl', '-O', 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'])\n",
    "    call(['unzip', 'ml-100k.zip'])\n",
    "    \n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(file_path, sep = '\\t', names=names)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the only data that we have is how each user interacted or rated each item.   \n",
    "Given this information, collaborative filtering will start by constructing a user-item matrix with each distinct user being the row, item being the column and the value for each cell will simply be the rating that the user gave to the item.   \n",
    "Apart from building the matrix, we will also print out some other information to help us understand our data a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T01:32:33.594312Z",
     "start_time": "2019-08-27T01:32:33.422022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensition:  (943, 1682)\n",
      "sparsity: 6.3%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the rating matrix r_{ui}\n",
    "# remember to subtract the user and item id by 1 since the indices starts from 0\n",
    "n_users = df['user_id'].unique().shape[0]\n",
    "n_items = df['item_id'].unique().shape[0]\n",
    "# initialize\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples(index=False): # iterrowよりも高速\n",
    "    ratings[row.user_id-1, row.item_id-1] = row.rating\n",
    "\n",
    "# compute the no-zero elements in the rating matrix\n",
    "matrix_size = np.prod(ratings.shape)\n",
    "interaction = np.flatnonzero(ratings).shape[0] # retrun \"indices\" tha are non-zero\n",
    "sparsity = (interaction/matrix_size) * 100\n",
    "\n",
    "print('dimensition: ', ratings.shape)\n",
    "print('sparsity: {:.1f}%'.format(sparsity))\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above, we know there are 943 unique users, 1682 unique items.   \n",
    "Within the rating matrix, only 6.3% of the cells have a value, although we filled in empty ratings as 0, we should **not** assume these values to truly be zero.   \n",
    "More appropriately, they are just missing entries. This kind of sparsity is extremely common in recommendation system, where people seldom give ratings to things that they have purchased.   \n",
    "One thing to note is that if the sparsity of the matrix is **below 1% (rule of thumb), then the dataset might be too sparse to perform any sort of modeling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T01:37:55.572801Z",
     "start_time": "2019-08-27T01:37:55.357836Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.sum(ratings != 0, axis=1), histtype='stepfilled', bins=30,\n",
    "            alpha=0.85, label='# of ratings', color='#7A68A6', normed=True)\n",
    "plt.axvline(x = 10, color='black', linestyle='--')\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the histogram tells us that every user has given at least more than 10 ratings, we will use this to perform the train/test split of the data for testing the algorithm that we'll build later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One tricky thing about splitting the data into training and testing is that:   \n",
    "In supervise machine learning we normally build the trainining and testing holdout set by randomly splitting the rows. In those cases, this idea works, because we have a model with features/target that we are trying to fit a function to.   \n",
    "\n",
    "For recommender systems with collaborative filtering (no features), this just **won't work** anymore, because all of the items/users need to be available when the model is first built. So what we do instead is **mask a random sample of the user/item ratings** to validate and compare how well the recommender system did in predicting the ratings of those masked values. In our case, given **we already know each user has given more than 10 ratings**, what we'll do is for every user, we **remove 10 of the item ratings and and assign them to the test set**. The testing matrix is printed below, as hopefully, you can see that some of the values are indeed different from the original rating matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T01:55:26.578804Z",
     "start_time": "2019-08-27T01:55:26.574627Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_test(ratings):\n",
    "    \"\"\"\n",
    "    split into training and test sets,\n",
    "    remove 10 ratings from each user\n",
    "    and assign them to the test set\n",
    "    \"\"\"\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_index = np.random.choice(np.flatnonzero(ratings[user]), size=10, replace=False)\n",
    "        \n",
    "        train[user, test_index] = 0.0 # 学習データからは削除\n",
    "        test[user, test_index] = ratings[user, test_index]\n",
    "        \n",
    "    # assert that training and testing set are truly disjoint\n",
    "    # trainとtestの同じ位置の各要素の積をとり，全て０となるかをチェック\n",
    "    # testはtrainのうち各ユーザ１０個ずつテストデータをとり，trainはその要素を0とする\n",
    "    assert np.all(train * test == 0)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T04:23:16.201093Z",
     "start_time": "2019-08-27T04:23:15.544067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = create_train_test(ratings)\n",
    "del ratings # save memory\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization with ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we had a user-item matrix,  $R$  where nonzero elements of the matrix are ratings that a user has given an item.  \n",
    "What Matrix Factorization does is it decomposes a large matrix into products of matrices, namely,  $R=U×V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix factorization assumes that:\n",
    "- Each user can be described by  $d$  features. For example, feature 1 might be a referring to how much each user likes disney movies.\n",
    "- Each item, movie in this case, can be described by an analogous set of  $d$  features. To correspond to the above example, feature 1 for the movie might be a number that says how close the movie is to a disney movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cool thing about this is that, we do not know what these features are nor do we have to determine them beforehand, which is why these features are often refer to as latent features.   \n",
    "Next, we also don't know how many latent features are optimal for the task at hand.   \n",
    "Thus, we can use random search or grid search or other fancy techniques to perform hyperparameter tuning and determine the best number for  $d$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given all those information, the next question is: how do we learn the user matrix,  $U$ , and item matrix,  $V$ ?  \n",
    "Well, like a lot of machine learning algorithm, by minimizing a loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by denoting our  d  feature user into math by letting a user  u  take the form of a  1×$d$ -dimensional vector  $x_u$ . These for often times referred to as latent vectors or low-dimensional embeddings.  \n",
    "Similarly, an item $i$ can be represented by a  1×$d$ -dimensional vector  $y_i$ . And the rating that we predict user $u$ will give for item $i$ is just the dot product of the two vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat r_{ui} = \\vec{x_u} \\vec{y_i}^T = \\sum_d x_{ud}y_{di}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where  $\\hat r_{ui}$  represents our prediction for the true rating  $r_{ui}$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will choose a objective function to minimize the square of the difference between all ratings in our dataset ($S$) and our predictions. This produces a objective function of the form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L = \\sum_{u,i\\in{S}}(\\vec{r_{ui}} - \\vec{x_u} \\vec{y_i}^T)^2 + \\lambda(\\sum_u|\\vec{x_u}|^2 + \\sum_i|\\vec{y_i}|^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've added on two  $L_2$  regularization terms, with $λ$ controlling the strength at the end to prevent overfitting of the user and item vectors.  \n",
    "$λ$, is another hyperparameter that we'll have to search for to determine the best value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we formalize our objective function, we'll introduce the **Alternating Least Squares with Weighted Regularization (ALS-WR)** method for optimizing it.  \n",
    "The way it works is we start by treating one set of latent vectors as constant. For this example, we'll pick the item vectors, $y_i$ . We then take the derivative of the loss function with respect to the other set of vectors, the user vectors,  $x_u$ and solve for the non-constant vectors (the user vectors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial \\vec{x_u}} = -2\\sum_{i}(\\vec{r_{ui}} - \\vec{x_u} \\vec{y_i}^T)\\vec{y_i} + 2\\lambda\\vec{x_u} = 0$$\n",
    "$$= -(\\vec{r_u}-\\vec{x_u}Y^T)Y + \\lambda\\vec{x_u} = 0$$\n",
    "$$= \\vec{x_u}(Y^TY+\\lambda I) = \\vec{r_u}Y$$\n",
    "$$= \\vec{x_u} =  \\vec{r_u}Y(Y^TY+\\lambda I)^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The row vector $r_u$ represents users $u$'s row from the ratings matrix with all the ratings for all the items (so it has dimension  1×$n$ )  \n",
    "- We introduce the symbol $Y$, with dimensions $n×d$ , to represent all item row vectors vertically stacked on each other\n",
    "- Lastly, $I$ is the identity matrix which has dimension $d×d$ to ensure the matrix multiplication's dimensionality will be correct when we add the $λ$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the alternating part: With these newly updated user vectors in hand, in the next round, we hold them as constant, and take the derivative of the loss function with respect to the previously constant vectors (the item vectors). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial \\vec{y_i}} = \\vec{y_i} =  \\vec{r_i}X(X^TX+\\lambda I)^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we alternate back and forth and carry out this two-step process until convergence.  \n",
    "The reason we alternate is, optimizing user latent vectors, $U$, and item latent vectors $V$ simultaneously is hard to solve (**NP hardness**).  \n",
    "If we fix $U$ or $V$ and tackle one problem at a time, we potentially turn it into a easier sub-problem. Just to summarize it, ALS works by:\n",
    "- Initialize the user latent vectors, $U$, and item latent vectors $V$ with **randomly**\n",
    "- Fix $U$ and solve for $V$\n",
    "- Fix $V$ and solve for  $U$\n",
    "- Repeat step 2 and 3 until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our equations, let's program this thing up!  \n",
    "We'll set the model to use **20 factors** and a **regularization value of 0.01 (chosen at random)** and train it for **100 iterations** and compute the **mean square error** on the train and test set to assess algorithm convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T04:40:44.658252Z",
     "start_time": "2019-08-28T04:40:44.649740Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExplicitMF():\n",
    "    \"\"\"\n",
    "    Train a matrix factorization mode using Alternating Least Squares to predict empty entries in a matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    n_iters : int\n",
    "        number of iterations to train the algoritm\n",
    "        \n",
    "    n_factors : int\n",
    "        number of latent factors to use in matrix\n",
    "        factorization model, some machine-learning libraries denote this as 'rank'\n",
    "        \n",
    "    reg : float\n",
    "        regularization term for item/user latent factors, since lambda is a keyword in python we use reg instead\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_iters, n_factors, reg):\n",
    "        self.reg = reg\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "        \n",
    "    def fit(self, train, test):\n",
    "        \"\"\"\n",
    "        pass in training and testing at the same time to record model convergence,\n",
    "        assuming both dataset is in the form of User x Item matrix with cells as ratings\n",
    "        \"\"\"\n",
    "        self.n_user, self.n_item = train.shape\n",
    "        self.user_factors = np.random.random((self.n_user, self.n_factors))\n",
    "        self.item_factors = np.random.random((self.n_item, self.n_factors))\n",
    "        \n",
    "        # record the training and testing mse for every iteration to show convergence later (usually, not worth it for production)\n",
    "        self.test_mse_record = []\n",
    "        self.train_mse_record = []\n",
    "        for it in range(self.n_iters):\n",
    "            self.user_factors = self._als_step(train, self.user_factors, self.item_factors)\n",
    "            self.item_factors = self._als_step(train.T, self.item_factors, self.user_factors)\n",
    "            predictions = self.predict()\n",
    "            test_mse = self.compute_mse(test, predictions)\n",
    "            train_mse = self.compute_mse(train, predictions)\n",
    "            self.test_mse_record.append(test_mse)\n",
    "            self.train_mse_record.append(train_mse)\n",
    "            print('iter: {}, test_mse: {}, train_mse: {}'.format(it+1, test_mse, train_mse))\n",
    "            \n",
    "        return self\n",
    "            \n",
    "            \n",
    "    def _als_step(self, ratings, solve_vecs, fixed_vecs):\n",
    "        \"\"\"\n",
    "        when updating the user matrix, the item matrix is the fixed vector and vice varsa\n",
    "        \"\"\"\n",
    "        A = fixed_vecs.T.dot(fixed_vecs) + np.eye(self.n_factors) * self.reg\n",
    "        b = ratings.dot(fixed_vecs)\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        solve_vecs = b.dot(A_inv)\n",
    "        return solve_vecs\n",
    "    \n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        predict ratings for every user and item\n",
    "        \"\"\"\n",
    "        pred = self.user_factors.dot(self.item_factors.T)\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_mse(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        ignore zero terms prior to comparing the mse\n",
    "        \"\"\"\n",
    "        mask = np.nonzero(y_true)\n",
    "        mse = mean_squared_error(y_true[mask], y_pred[mask])\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T08:27:20.638961Z",
     "start_time": "2019-08-27T08:27:20.635784Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(model):\n",
    "    \"\"\"\n",
    "    visualize the training/testing loss\n",
    "    \"\"\"\n",
    "    linewidth = 3\n",
    "    plt.plot(model.test_mse_record, label='Test', linewidth=linewidth)\n",
    "    plt.plot(model.train_mse_record, label='Train', linewidth=linewidth)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T08:27:25.173997Z",
     "start_time": "2019-08-27T08:27:21.416654Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1, test_mse: 9.66617032872331, train_mse: 5.371658662257342\n",
      "iter: 2, test_mse: 8.532033989615, train_mse: 4.208043738335672\n",
      "iter: 3, test_mse: 8.464862082924245, train_mse: 4.060217804495945\n",
      "iter: 4, test_mse: 8.445007728166754, train_mse: 4.0084207943468035\n",
      "iter: 5, test_mse: 8.436663691719303, train_mse: 3.983698810608167\n",
      "iter: 6, test_mse: 8.433352368390384, train_mse: 3.969927961726057\n",
      "iter: 7, test_mse: 8.431965433236424, train_mse: 3.9614800575923605\n",
      "iter: 8, test_mse: 8.431139155110195, train_mse: 3.955984638937514\n",
      "iter: 9, test_mse: 8.430415319400526, train_mse: 3.9522640158992615\n",
      "iter: 10, test_mse: 8.429718782271141, train_mse: 3.9496585532232307\n",
      "iter: 11, test_mse: 8.429087142364219, train_mse: 3.9477743174636224\n",
      "iter: 12, test_mse: 8.42856212679794, train_mse: 3.946367764683358\n",
      "iter: 13, test_mse: 8.42816162810192, train_mse: 3.94528447352447\n",
      "iter: 14, test_mse: 8.427881936017737, train_mse: 3.9444242684847985\n",
      "iter: 15, test_mse: 8.427706862451844, train_mse: 3.9437207570402535\n",
      "iter: 16, test_mse: 8.427615602589304, train_mse: 3.943129068849647\n",
      "iter: 17, test_mse: 8.427587629998065, train_mse: 3.9426183618312622\n",
      "iter: 18, test_mse: 8.42760508404124, train_mse: 3.9421671495897757\n",
      "iter: 19, test_mse: 8.427653540642474, train_mse: 3.9417603261244647\n",
      "iter: 20, test_mse: 8.427721918372827, train_mse: 3.9413872264448275\n",
      "iter: 21, test_mse: 8.427802015652714, train_mse: 3.9410403289416487\n",
      "iter: 22, test_mse: 8.427887956193253, train_mse: 3.940714362673609\n",
      "iter: 23, test_mse: 8.427975672814254, train_mse: 3.9404056762447963\n",
      "iter: 24, test_mse: 8.428062475304639, train_mse: 3.940111780750197\n",
      "iter: 25, test_mse: 8.42814670633939, train_mse: 3.9398310126255187\n",
      "iter: 26, test_mse: 8.428227472987992, train_mse: 3.939562282208649\n",
      "iter: 27, test_mse: 8.428304437733555, train_mse: 3.939304885784411\n",
      "iter: 28, test_mse: 8.428377654777254, train_mse: 3.9390583660540206\n",
      "iter: 29, test_mse: 8.428447440823096, train_mse: 3.9388224102826745\n",
      "iter: 30, test_mse: 8.42851427275458, train_mse: 3.938596778013853\n",
      "iter: 31, test_mse: 8.428578707026343, train_mse: 3.938381251918839\n",
      "iter: 32, test_mse: 8.428641317163219, train_mse: 3.9381756065089104\n",
      "iter: 33, test_mse: 8.428702646667569, train_mse: 3.9379795903242325\n",
      "iter: 34, test_mse: 8.42876317511013, train_mse: 3.937792917959407\n",
      "iter: 35, test_mse: 8.428823295413721, train_mse: 3.937615268949833\n",
      "iter: 36, test_mse: 8.428883300470213, train_mse: 3.937446291144231\n",
      "iter: 37, test_mse: 8.42894337734162, train_mse: 3.9372856067268254\n",
      "iter: 38, test_mse: 8.42900360742537, train_mse: 3.9371328195217514\n",
      "iter: 39, test_mse: 8.429063971123293, train_mse: 3.9369875226074944\n",
      "iter: 40, test_mse: 8.429124355738173, train_mse: 3.936849305590269\n",
      "iter: 41, test_mse: 8.429184565519309, train_mse: 3.936717761135974\n",
      "iter: 42, test_mse: 8.429244332975896, train_mse: 3.9365924905482976\n",
      "iter: 43, test_mse: 8.429303330763094, train_mse: 3.936473108314914\n",
      "iter: 44, test_mse: 8.429361183612805, train_mse: 3.9363592456347445\n",
      "iter: 45, test_mse: 8.429417479924734, train_mse: 3.93625055299643\n",
      "iter: 46, test_mse: 8.429471782751982, train_mse: 3.9361467019101415\n",
      "iter: 47, test_mse: 8.42952364001006, train_mse: 3.936047385909087\n",
      "iter: 48, test_mse: 8.429572593810725, train_mse: 3.9359523209389082\n",
      "iter: 49, test_mse: 8.429618188875754, train_mse: 3.935861245247671\n",
      "iter: 50, test_mse: 8.42965998002357, train_mse: 3.935773918878989\n",
      "iter: 51, test_mse: 8.429697538747133, train_mse: 3.9356901228588557\n",
      "iter: 52, test_mse: 8.429730458917158, train_mse: 3.935609658154053\n",
      "iter: 53, test_mse: 8.429758361653684, train_mse: 3.935532344467953\n",
      "iter: 54, test_mse: 8.429780899412659, train_mse: 3.935458018928354\n",
      "iter: 55, test_mse: 8.42979775933515, train_mse: 3.935386534712166\n",
      "iter: 56, test_mse: 8.429808665905323, train_mse: 3.9353177596433\n",
      "iter: 57, test_mse: 8.429813382961548, train_mse: 3.935251574792895\n",
      "iter: 58, test_mse: 8.429811715102453, train_mse: 3.935187873105066\n",
      "iter: 59, test_mse: 8.429803508527923, train_mse: 3.9351265580663983\n",
      "iter: 60, test_mse: 8.429788651353464, train_mse: 3.935067542433308\n",
      "iter: 61, test_mse: 8.429767073435444, train_mse: 3.9350107470280737\n",
      "iter: 62, test_mse: 8.42973874574458, train_mse: 3.9349560996115533\n",
      "iter: 63, test_mse: 8.429703679325206, train_mse: 3.93490353383828\n",
      "iter: 64, test_mse: 8.42966192387875, train_mse: 3.934852988297708\n",
      "iter: 65, test_mse: 8.429613566010605, train_mse: 3.934804405643694\n",
      "iter: 66, test_mse: 8.429558727180854, train_mse: 3.934757731812887\n",
      "iter: 67, test_mse: 8.429497561400126, train_mse: 3.9347129153313953\n",
      "iter: 68, test_mse: 8.42943025271268, train_mse: 3.9346699067080704\n",
      "iter: 69, test_mse: 8.429357012509092, train_mse: 3.934628657911706\n",
      "iter: 70, test_mse: 8.429278076710935, train_mse: 3.934589121928656\n",
      "iter: 71, test_mse: 8.429193702869023, train_mse: 3.934551252396637\n",
      "iter: 72, test_mse: 8.429104167215764, train_mse: 3.9345150033098513\n",
      "iter: 73, test_mse: 8.429009761710246, train_mse: 3.9344803287901384\n",
      "iter: 74, test_mse: 8.428910791112372, train_mse: 3.934447182918421\n",
      "iter: 75, test_mse: 8.42880757011961, train_mse: 3.9344155196205417\n",
      "iter: 76, test_mse: 8.42870042059656, train_mse: 3.934385292601367\n",
      "iter: 77, test_mse: 8.428589668924127, train_mse: 3.9343564553210957\n",
      "iter: 78, test_mse: 8.428475643491108, train_mse: 3.934328961007727\n",
      "iter: 79, test_mse: 8.428358672347203, train_mse: 3.9343027626998324\n",
      "iter: 80, test_mse: 8.428239081032448, train_mse: 3.9342778133140595\n",
      "iter: 81, test_mse: 8.428117190594097, train_mse: 3.934254065732054\n",
      "iter: 82, test_mse: 8.427993315798329, train_mse: 3.9342314729019585\n",
      "iter: 83, test_mse: 8.427867763540482, train_mse: 3.934209987949971\n",
      "iter: 84, test_mse: 8.427740831454358, train_mse: 3.934189564297983\n",
      "iter: 85, test_mse: 8.427612806718066, train_mse: 3.9341701557837263\n",
      "iter: 86, test_mse: 8.42748396505144, train_mse: 3.9341517167803604\n",
      "iter: 87, test_mse: 8.427354569897648, train_mse: 3.934134202312888\n",
      "iter: 88, test_mse: 8.427224871779972, train_mse: 3.93411756816924\n",
      "iter: 89, test_mse: 8.42709510782308, train_mse: 3.934101771004284\n",
      "iter: 90, test_mse: 8.42696550142716, train_mse: 3.9340867684354244\n",
      "iter: 91, test_mse: 8.426836262082405, train_mse: 3.934072519128836\n",
      "iter: 92, test_mse: 8.426707585310899, train_mse: 3.934058982875621\n",
      "iter: 93, test_mse: 8.426579652722829, train_mse: 3.934046120657625\n",
      "iter: 94, test_mse: 8.426452632173913, train_mse: 3.9340338947026963\n",
      "iter: 95, test_mse: 8.42632667801125, train_mse: 3.9340222685295667\n",
      "iter: 96, test_mse: 8.426201931395275, train_mse: 3.934011206982608\n",
      "iter: 97, test_mse: 8.426078520685921, train_mse: 3.9340006762568605\n",
      "iter: 98, test_mse: 8.425956561882042, train_mse: 3.933990643913905\n",
      "iter: 99, test_mse: 8.425836159103595, train_mse: 3.9339810788891674\n",
      "iter: 100, test_mse: 8.425717405107184, train_mse: 3.9339719514913374\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als = ExplicitMF(n_iters=100, n_factors=40, reg=0.01)\n",
    "als.fit(train, test)\n",
    "plot_learning_curve(als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that ALS converges after **a few** sweeps, which is one of the main reason for its popularity.  \n",
    "**Fast**, thus **scalable** to bigger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
